\chapter{Features}
\label{features}

Table~\ref{feature-table} contains a comprehensive list of the features in the
XTAG grammar and their possible values.

\footnotesize
\begin{table}[hbt]
\centering
\begin{tabular}{|l|l|}
\hline
Feature&Value\\
\hline
\hline
$<$agr 3rdsing$>$&$+,-$\\
$<$agr num$>$&plur,sing\\
$<$agr pers$>$&1,2,3\\
$<$assign-case$>$&nom,acc,none\\
$<$assign-comp$>$&that,whether,if,for,rel,inf\_nil,ind\_nil,ecm,ppart\_nil\\
$<$card$>$&$+,-$\\
$<$case$>$&nom,acc,gen,none\\
$<$comp$>$&that,whether,if,for,rel,inf\_nil,ind\_nil,nil\\
$<$compar$>$&$+,-$\\
$<$compl$>$&$+,-$\\
$<$conj$>$&and,or,none,nil\\
$<$const$>$&$+,-$\\
$<$contr$>$&$+,-$\\
$<$control$>$&no value, indexing only\\
$<$decreas$>$&$+,-$\\
$<$definite$>$&$+,-$\\
$<$displ-const$>$&$+,-$\\
$<$equiv$>$&$+,-$\\
$<$extracted$>$&$+,-$\\
$<$gen$>$&$+,-$\\
$<$inv$>$&$+,-$\\
$<$invlink$>$&\\
$<$mainv$>$&$+,-$\\
$<$mode$>$&base,ger,ind,inf,imp,nom,ppart,prep,sbjunt\\
$<$neg$>$&$+,-$\\
$<$passive$>$&$+,-$\\
$<$pred$>$&$+,-$\\
$<$pron$>$&$+,-$\\
$<$punct bal$>$&dquote,squote,nil\\
$<$punct contains dquote$>$&$+,-$\\
$<$punct contains squote$>$&$+,-$\\
$<$punct struct$>$&comma,dash,colon,none,nil\\
$<$punct term$>$&per,qmark,excl,none,nil\\
$<$quan$>$&$+,-$\\
$<$rel-clause$>$&$+,-$\\
$<$rel-pron$>$&$+,-$\\
$<$select-mode$>$&ind,inf,ppart,ger\\
$<$sub-conj$>$&ind1,ind2,ind3,inf1,inf2,ger,nil\\
$<$super$>$&$+,-$\\
$<$tense$>$&pres,past\\
$<$trace$>$&no value, indexing only\\
$<$trans$>$&$+,-$\\
$<$weak$>$&$+,-$\\
$<$wh$>$&$+,-$\\
\hline
\end{tabular}
\caption{List of features and their possible values}
\label{feature-table}
\end{table}

\normalsize



\section{Agreement}
{\bf $\langle$agr$\rangle$} is a complex feature.
It can have as its subfeatures:\\
{\bf $\langle$agr 3rdsing$\rangle$}, possible values: {\bf $+/-$ }\\
{\bf $\langle$agr num$\rangle$}, possible values: {\bf $plur,sing$ }\\
{\bf $\langle$agr pers$\rangle$}, possible values: {\bf $1,2,3$ }

These features are used to ensure agreement between a verb and its subject.

Where does it occur:\\
Nouns comes specified from the lexicon with their {\bf $\langle$agr$\rangle$}
features. e.g. {\em books} is {\bf $\langle$agr 3rdsing$\rangle$: -},
{\bf $\langle$agr num$\rangle$: plur}, 
and {\bf $\langle$agr pers$\rangle$: 3}. 

The {\bf $\langle$agr$\rangle$} features of a noun are transmitted up the 
NP tree by the following equation:\\
{\bf NP.b:$\langle$agr$\rangle =$ N.t:$\langle$agr$\rangle$}

Agreement between a verb and its subject is mediated by the following feature
equations:

\enumsentence{ {\bf NP_{subj}:$\langle$agr$\rangle =$ VP.t:$\langle$agr$\rangle$}}


\enumsentence{ {\bf VP.b:$\langle$agr$\rangle =$ V.t:$\langle$agr$\rangle$}}

Agreement has to be done as a two step process because whether the
verb agrees with the subject or not depends upon whether some auxiliary verb
adjoins in and upon what the {\bf $\langle$agr$\rangle$} specification of 
the verb is. 

Verbs also come specified from the lexicon with their {\bf $\langle$agr$\rangle$}
features e.g. the {\bf $\langle$agr$\rangle$} features of the
verb {\em sings} are {\bf $\langle$agr 3rdsing$\rangle$: +},
{\bf $\langle$agr num$\rangle$: sing}, 
and {\bf $\langle$agr pers$\rangle$: 3}; 
Non-finite forms of the verb {\em sing} e.g. {\em singing} do not come with
an {\bf $\langle$agr$\rangle$} feature specification. 

\subsection{Agreement and Movement}
The {\bf $\langle$agr$\rangle$} features of a moved NP and its trace 
are co-indexed. This captures the fact that movement does not disrupt 
a pre-existing agreement relationship between an NP and a verb.

\enumsentence{ \ [Which boys]_{i} does John think [t_{i} are/*is intelligent]?}



\section{Case}
There are two features responsible for case-assignment:\\
{\bf $\langle$case$\rangle$}, possible values: {\bf nom, acc, gen, none}\\
{\bf $\langle$assign-case$\rangle$}, possible values: {\bf nom, acc, none}

Case assigners (prepositions, verbs, also
VP, S and PP nodes) have an {\bf $\langle$assign-case$\rangle$}
case feature. Phrases and lexical items
that have case i.e. Ns and NPs have a {\bf $\langle$case$\rangle$}
feature.

Case assignment by prepositions involves the following equations:

\enumsentence{ {\bf PP.b:$\langle$assign-case$\rangle =$ P.t:$\langle$case$\rangle$}}


\enumsentence{ {\bf NP.t:$\langle$case$\rangle =$ P.t:$\langle$case$\rangle$}}

Prepositions come specified from the lexicon with their {\bf $\langle$assign-case$\rangle$}
feature.

\enumsentence{ {\bf P.b:$\langle$assign-case$\rangle =$ acc}}


Case assignment by verbs has two parts: assignment of case to the object(s) and
assignment of case to the subject. Assignment of case to the object is simpler.
Verbs assign only accusative case to their NP objects (direct or indirect).
Hence this is built into the tree and not put into the lexical entry of
each individual verb.

\enumsentence{ {\bf NP_{object}.t:$\langle$case$\rangle =$ acc}}

Assignment of case to the subject involves the following two equations.

\enumsentence{ {\bf NP_{subj}:$\langle$case$\rangle =$ VP.t:$\langle$assign-case$\rangle$}}


\enumsentence{ {\bf VP.b:$\langle$assign-case$\rangle =$ V.t:$\langle$assign-case$\rangle$}}

This is a two step process - the final case assigned to the subject depends upon
the {\bf $\langle$assign-case$\rangle$} feature of the verb as well as whether an
auxiliary verb adjoins in. 

Finite verbs like {\em sings} have {\bf nom} as the value of their
{\bf $\langle$assign-case$\rangle$} feature. Non-finite verbs have {\bf none}
as the value of their
{\bf $\langle$assign-case$\rangle$} feature. So if no auxiliary adjoins in,
the only subject they can have is {\bf PRO} which is the only NP with
{\bf none}
as the value its {\bf $\langle$case$\rangle$} feature.

\subsection{ECM}
Certain verbs e.g. {\em want, believe, consider} etc. and one complementizer
{\em for} are able to assign case to the subject of their complement clause. 

The complementizer {\em for}, like the preposition {\em for}, has the 
{\bf $\langle$assign-case$\rangle$} feature of its complement set
to {\bf acc}. Since the {\bf $\langle$assign-case$\rangle$} feature of
the root S_{r} and the {\bf $\langle$case$\rangle$} feature of the 
NP subject are co-indexed, this leads to the subject being assigned 
accusative case.

ECM verbs have the {\bf $\langle$assign-case$\rangle$}  feature of their
foot S node set to {\bf acc}. The co-indexation between the 
{\bf $\langle$assign-case$\rangle$} feature of
the root S_{r} and the {\bf $\langle$case$\rangle$} feature of the NP subject
leads to the subject being assigned accusative case.

\subsection{Agreement and Case}
The {\bf $\langle$case$\rangle$} features of a moved NP and its trace 
are co-indexed. This captures the fact that movement does not disrupt 
a pre-existing relationship of case-assignment between a verb and an NP.

\enumsentence{ Her_{i}/*She_{i}, I think that Odo like t_{i}.}


\section{Extraction and Inversion}
{\bf $\langle$extracted$\rangle$}, possible vales are {\bf $+/-$}

All sentential trees with extracted components, with the
exception of relative clauses
are marked {\bf S.b$\langle$extracted$\rangle = +$} at their top S node. 
This feature is used to impose subcategorizational constraints. 
Certain verbs like {\em wonder} can only take interrogative complements,
other verbs such as {\em know} can take both interrogative complements,
and yet other verbs like {\em think} can only take non-interrogative complements.

{\bf $\langle$trace$\rangle$}: this feature is not assigned any value and
is used to co-index moved NPs and their traces which are marked by
$\epsilon$.

{\bf $\langle$wh$\rangle$}: possible values are {\bf $+/-$}\\
NPs like {\em who}, {\em what} etc. come marked
from the lexicon  with a value of {\bf $+$} for the feature {\bf $\langle$wh$\rangle$}.
Non {\em wh}-NPs have {\bf $-$} as the value of their 
{\bf $\langle$wh$\rangle$} feature. 

The {\bf $\langle$wh$\rangle$} feature
is propagated up by possessives -  e.g. the $+$ {\bf $\langle$wh$\rangle$}
feature of the determiner {\em which} in {\em which boy} is propagated up
to the level of the NP so that the value of the {\bf $\langle$wh$\rangle$} feature
of the entire NP is $+${\bf $\langle$wh$\rangle$}. This process is recursive
e.g. {\em which boy's mother}, {\em which boy's mother's sister}. 

The {\bf $\langle$wh$\rangle$} feature
is also propagated up PPs. Thus the PP {\em to whom} has $+$ as the value of its 
{\bf $\langle$wh$\rangle$} feature. 

In trees with extracted NPs, the {\bf $\langle$wh$\rangle$} feature of the
root node S node is equated with the {\bf $\langle$wh$\rangle$} feature
of the extracted NPs. 

The {\bf $\langle$wh$\rangle$} feature is also used to get the correct
inversion patterns.

\subsection{Inversion Pt.1}
The following three features are used to ensure the correct pattern of
inversion:\\
{\bf $\langle$wh$\rangle$}: possible values are {\bf $+/-$}\\
{\bf $\langle$inv$\rangle$}: possible values are {\bf $+/-$}\\
{\bf $\langle$invlink$\rangle$}: possible values are {\bf $+/-$}

Facts to be captured:\\
1. No inversion with topicalization\\
2. No inversion with matrix extracted subject {\em wh}-questions\\
3. Inversion with matrix extracted object {\em wh}-questions\\
4. Inversion with all matrix {\em wh}-questions involving extraction from an
embedded clause\\
5. No inversion in embedded questions

6. No matrix subject topicalizations.

Consider a tree with object extraction, where NP is the extracted NP. 
The following feature equations are used:\\

\enumsentence{ {\bf S_{q}.b:$\langle$wh$\rangle =$ NP.t:$\langle$wh$\rangle$}\label{inv1}}
\enumsentence{ {\bf S_{q}.b:$\langle$invlink$\rangle =$  S_{q}.b:$\langle$inv$\rangle$}\label{inv2}}
\enumsentence{ {\bf S_{q}.b:$\langle$inv$\rangle =$  S_{r}.t:$\langle$inv$\rangle$}\label{inv3}}
\enumsentence{ {\bf S_{r}.b:$\langle$inv$\rangle = -$}\label{inv4}}

{\bf Root restriction}: A restriction is imposed on the final root node 
of any XTAG derivation which equates the {\bf $\langle$wh$\rangle$}
feature and the {\bf $\langle$invlink$\rangle$} feature of the final
root node. 

If the extracted NP is not a {\em wh}-word i.e. its {\bf $\langle$wh$\rangle$}
feature has the value $-$, at the end of the derivation, 
{\bf S_{q}.b:$\langle$wh$\rangle$} will also have the value $-$. Because of
the root constraint {\bf S_{q}.b:$\langle$wh$\rangle$} will be equated 
to {\bf S_{q}.b:$\langle$invlink$\rangle$} which will also come to have 
the value $-$. Then, by (\ref{inv3}), {\bf S_{r}.t:$\langle$inv$\rangle$} 
will acquire the value $-$. This will unify with {\bf S_{r}.b:$\langle$inv$\rangle$}
which has the value $-$ (cf. \ref{inv4}). Consequently, no auxiliary verb
adjunction will be forced. Hence, there will never be inversion in topicalization.

If the extracted NP is a {\em wh}-word i.e. its {\bf $\langle$wh$\rangle$} 
feature has the value $+$, at the end of the derivation, 
{\bf S_{q}.b:$\langle$wh$\rangle$} will also have the value $+$. Because of
the root constraint {\bf S_{q}.b:$\langle$wh$\rangle$} will be equated 
to {\bf S_{q}.b:$\langle$invlink$\rangle$} which will also come to have
the value $+$. Then, by (\ref{inv3}), {\bf S_{r}.t:$\langle$inv$\rangle$} 
will acquire the value $+$. This will not unify with {\bf S_{r}.b:$\langle$inv$\rangle$}
which has the value $+$ (cf. \ref{inv4}). Consequently, the adjunction
of an auxiliary verb is forced upon us leading to inversion.

Inversion will still take place even if the extraction is from an embedded
clause.

\enumsentence{ Who_{i} does Loida think [Miguel likes t_{i}]}

This is because the adjoined tree's root node will also have its 
{\bf S_{r}.b:$\langle$inv$\rangle$} set to $-$. 


Note that inversion is only forced upon us because S_{q} is the final root node
nd the {\bf Root restriction} applies. In embedded environments , the 
root restriction would not apply and the feature clash that forces adjunction
would not take place. 

The {\bf $\langle$invlink$\rangle$} feature is not present in subject extractions.
Consequently there is no inversion in subject questions.

Subject topicalizations are blocked by setting the 
{\bf $\langle$wh$\rangle$} feature of the extracted NP to $+$ i.e. only
{\em wh}-phrases can go in this location. 

\subsection{Inversion Pt. 2}
{\bf $\langle$displ-const$\rangle$}:\\
Possible values: {\bf [set1: +], [set1: -]}\\
In the previous section, we saw how inversion is triggered using the
{\bf $\langle$invlink$\rangle$}, {\bf $\langle$inv$\rangle$},
{\bf $\langle$wh$\rangle$} features. Inversion involves movement
of the verb from V to C. This movement process is represented
using the {\bf $\langle$displ-const$\rangle$} feature which is
used to simulate Multi Component TAGs. 
\footnote{The {\bf $\langle$displ-const$\rangle$} feature is also used 
in the ECM analysis.}

The {\bf $\langle$displ-const$\rangle$} feature is used to ensure
adjunction of two trees, which in this case are the auxiliary
tree corresponding to the moved verb (S adjunct) and the auxiliary tree
corresponding to the trace of the moved verb (VP adjunct). The following
equations are used:

\enumsentence{  {\bf S_{r}.b:$\langle$displ-const set1$\rangle = -$}\label{dis1}}
\enumsentence{  {\bf S.t:$\langle$displ-const set1$\rangle = +$}\label{dis2}}
\enumsentence{  {\bf VP.b:$\langle$displ-const set1$\rangle =$
          V.t:$\langle$displ-const set1$\rangle$}\label{dis3}}
\enumsentence{  {\bf V.b:$\langle$displ-const set1$\rangle = +$}\label{dis4}}
\enumsentence{  {\bf S_{r}.b:$\langle$displ-const set1$\rangle =$ 
          VP.t:$\langle$displ-const set1$\rangle$}\label{dis5}}


\section{Clause Type}
There are several features that mark clause type.
\footnote{We have already
seen one instance of a feature that marks clause-type:
{\bf $\langle$extracted$\rangle$}, which marks whether a certain S
involves extraction or not.} They are:\\
{\bf $\langle$mode$\rangle$}\\
{\bf $\langle$passive$\rangle$}: possible values are {\bf +/-}


{\bf $\langle$mode$\rangle$}: possible values are 
{\bf base, ger, ind, inf, imp, nom, ppart, prep, sbjnct}\\
The {\bf $\langle$mode$\rangle$} feature of a verb in its root form is
{\bf base}. The {\bf $\langle$mode$\rangle$} feature of a verb in its past 
participial form is {\bf ppart}, the {\bf $\langle$mode$\rangle$} feature of a 
verb in its progressive/gerundive form is {\bf ger}, 
the {\bf $\langle$mode$\rangle$} feature of a tensed verb is {\bf ind},
and the {\bf $\langle$mode$\rangle$} feature of a verb in the imperative 
is {\bf imp}. 

{\bf nom} is the {\bf $\langle$mode$\rangle$} value of AP/NP predicative trees
headed by a null copula. 
{\bf prep} is the {\bf $\langle$mode$\rangle$} value of PP predicative trees
headed by a null copula. 
Only the copula auxiliary tree and Raising verb auxiliary trees have 
{\bf nom/prep} as the {\bf $\langle$mode$\rangle$} feature specification of their
foot node. This allow them, and only them, to adjoin onto AP/NP/PP predicative
trees with null copulas. 

\subsection{Auxiliary Selection}
The {\bf $\langle$mode$\rangle$} feature is also used to state the
subcategorizational constraints between an auxiliary verb and its
complement. We model the following constraints:\\
{\em have} takes past participial complements\\
passive {\em be} takes past participial complements\\
active {\em be} takes progressive complements\\
modal verbs, {\em do}, and {\em to} take VPs headed by verbs in their
base form as their complements. 

An auxiliary verb transmits its own mode to its root and imposes its
subcategorizational restrictions on its complement i.e. on its foot node.
e.g. the auxiliary {\em have} in its infinitival form involves the
following equations:

\enumsentence{ {\bf VP_{r}.b:$\langle$mode$\rangle =$ 
          V.t:$\langle$mode$\rangle$}\label{mode1}}
\enumsentence{ {\bf  V.t:$\langle$mode$\rangle =$ base}\label{mode2}}
\enumsentence{ {\bf VP.b:$\langle$mode$\rangle =$ ppart}\label{mode3}}


{\bf $\langle$passive$\rangle$}: This feature is used to ensure 
that passives only have {\em be} as their auxiliary. Passive trees
start out with their {\bf $\langle$passive$\rangle$} feature as {\bf +}. 
This feature starts out at the level of the verb and is percolated
up to the level of the VP. This ensures that only auxiliary verbs
whose foot node has {\bf +} as their {\bf $\langle$passive$\rangle$} feature
can adjoin on a passive. Passive trees have {\bf ppart} as the
value of their {\bf $\langle$mode$\rangle$} feature. So the only trees
that we really have to worry about are trees whose foot nodes
have {\bf ppart} as the
value of their {\bf $\langle$mode$\rangle$} feature. There are two such trees
- the {\em be} tree and the {\em have} tree. The {\em be} tree is fine - its
foot node has {\bf +} as its {\bf $\langle$passive$\rangle$} feature,
the {\em have} tree is not ok, and it is blocked because its 
foot node has {\bf -} as its {\bf $\langle$passive$\rangle$} feature.

\section{Relative Clauses}
Features that are peculiar to the relative clause system are:\\
{\bf $\langle$select-mode$\rangle$}, possible values are {\bf ind, inf, ppart, ger}\\
{\bf $\langle$rel-pron$\rangle$}, possible values are {\bf +/-}\\
{\bf $\langle$rel-clause$\rangle$}, possible values are {\bf +/-}

{\bf $\langle$select-mode$\rangle$}:\\
Comps are lexically specified for {\bf $\langle$select-mode$\rangle$}.
In addition, the {\bf $\langle$select-mode$\rangle$} feature of a Comp
is equated to the {\bf $\langle$mode$\rangle$} feature of its
sister S node by the following equation:

\enumsentence{ {\bf Comp.t:$\langle$select-mode$\rangle =$ S_{t}.t:$\langle$mode$\rangle$}}


The lexical specifications of the Comps are shown below:
\begin{itemize}
\item $\epsilon$_{C}, {\bf Comp.t:$\langle$select-mode$\rangle
=$ind/inf/ger/ppart}
\item {\em that}, {\bf Comp.t:$\langle$select-mode$\rangle =$ind}
\item {\em for}, {\bf Comp.t:$\langle$select-mode$\rangle =$inf}
\end{itemize}

{\bf $\langle$rel-pron$\rangle$}:\\
There are additional constraints on where the null Comp $\epsilon$_{C}
can occur. The null Comp is not permitted in cases of subject
extraction unless there is an intervening clause or or
the relative clause is a reduced relative ({\bf mode = ppart/ger}).

To model this paradigm, the feature {\bf $\langle$rel-pron$\rangle$} is used in
conjunction with the following equations.


\ex
{\bf S_{r}.t:$\langle$rel-pron$\rangle =$ Comp.t:$\langle$rel-pron$\rangle$}\\
\ex
{\bf S_{r}.b:$\langle$rel-pron$\rangle =$ S_{r}.b:$\langle$mode$\rangle$}\\
\ex
{\bf Comp.b:$\langle$rel-pron$\rangle =$ppart/ger/adj-clause}
(for $\epsilon$_{C})

The full set of the equations above is only present in Comp
substitution trees involving subject extraction. So the following will
not be ruled out.

\ex
the toy [$\epsilon$_{i} [$\epsilon$_{C} [ Dafna likes t_i ]]]


The feature mismatch induced by the above equations
is not remedied by adjunction of just any S-adjunct
because all other S-adjuncts
are transparent to the {\bf $\langle$rel-pron$\rangle$} feature
because of the following equation:

\ex
{\bf S_{m}.b:$\langle$rel-pron$\rangle =$ S_{f}.t:$\langle$rel-pron$\rangle$}


{\bf $\langle$rel-clause$\rangle$}:\\
The Xtag analysis forces the adjunction of the determiner 
below the relative clause. This done by using the {\bf $\langle$rel-clause$\rangle$}
feature. The relevant equations are:

\enumsentence{ On the root of the RC: {\bf NP_{r}.b:$\langle$rel-clause$\rangle = +$}}
\enumsentence{ On the foot node of the 
Determiner tree: {\bf NP_{f}.t:$\langle$rel-clause$\rangle = -$}}




\section{Complementizer Selection}
The following features are used to ensure the appropriate distribution
of complementizers:
\\
{\bf $\langle$comp$\rangle$}, possible values: {\bf that, if, whether, for, rel, nil}\\
{\bf $\langle$assign-comp$\rangle$}, possible values: {\bf that, if, whether, for/ecm, 
rel, ind\_nil, inf\_nil}\\
{\bf $\langle$mode$\rangle$}, possible values: {\bf ind, inf, sbjnct, ger, base, ppart, 
nom, prep}\\
{\bf $\langle$wh$\rangle$}, possible values: {\bf +, -}

The value of the {\bf $\langle$comp$\rangle$} feature tells us what complementizer we 
are dealing with. The trees which introduce complementizers come 
specified from the lexicon with their 
{\bf $\langle$comp$\rangle$} feature and {\bf $\langle$assign-comp$\rangle$} 
feature. The {\bf $\langle$comp$\rangle$} of the Comp tree regulates 
what kind of tree goes above the Comp tree, while the 
{\bf $\langle$assign-comp$\rangle$} feature regulates what kind of tree
goes below.
e.g.
the following equations are used for {\em that}:

\enumsentence{ {\bf S_{c}.b:$\langle$comp$\rangle =$ Comp.t:$\langle$comp$\rangle$} }
\enumsentence{ {\bf S_{c}.b:$\langle$wh$\rangle =$ Comp.t:$\langle$wh$\rangle$}}
\enumsentence{ {\bf S_{c}.b:$\langle$mode$\rangle =$ ind/sbjnct}}
\enumsentence{ {\bf S_{r}.t:$\langle$assign-comp$\rangle =$ Comp.t:$\langle$comp$\rangle$}}
\enumsentence{ {\bf S_{r}.b:$\langle$comp$\rangle =$ nil}}

By specifying {\bf S_{r}.b:$\langle$comp$\rangle =$ nil}, we ensure that
complementizers do not adjoin onto other complementizers. The root node
of a complementizer tree always has its {\bf $\langle$comp$\rangle$} feature
set to a value other than {\bf nil}.

Trees that take clausal complements specify with the {\bf $\langle$comp$\rangle$} feature
on their foot node what kind of complementizer(s) they can take. 
The {\bf $\langle$assign-comp$\rangle$} feature of an S node is determined 
by the highest VP below the S node and the syntactic configuration
the S node is in. 

\subsection{Verbs with object sentential complements}
Finite sentential complements:
\footnote{
If the verb does not take subjunctive complements, the {\bf sbjnct}
specification will be absent.
}

\enumsentence{ {\bf S_{1}.t:$\langle$comp$\rangle =$ that/whether/if/nil}}
\enumsentence{ {\bf S_{1}.t:$\langle$mode$\rangle =$ ind/sbjnct}}
\enumsentence{ {\bf S_{1}.t:$\langle$assign-comp$\rangle =$ ind\_nil/inf\_nil}}

The presence of an overt complementizer is optional.

Non-finite sentential complements, do not permit {\em for}:

\enumsentence{ {\bf S_{1}.t:$\langle$comp$\rangle =$ nil}}
\enumsentence{ {\bf S_{1}.t:$\langle$mode$\rangle =$ inf}}
\enumsentence{ {\bf S_{1}.t:$\langle$assign-comp$\rangle =$ ind\_nil/inf\_nil}
}

Non-finite sentential complements, permit {\em for}:

\enumsentence{ {\bf S_{1}.t:$\langle$comp$\rangle =$ for/nil}}
\enumsentence{ {\bf S_{1}.t:$\langle$mode$\rangle =$ inf}}
\enumsentence{ {\bf S_{1}.t:$\langle$assign-comp$\rangle =$ ind\_nil/inf\_nil}}

Cases like `*I want for to win' are independently ruled out due to a 
case feature clash between the {\bf acc} assigned by {\em for} and the
intrinsic case feature {\bf none} on the PRO.

Non-finite sentential complements, ECM:

\enumsentence{ {\bf S_{1}.t:$\langle$comp$\rangle =$ nil}}
\enumsentence{ {\bf S_{1}.t:$\langle$mode$\rangle =$ inf}}
\enumsentence{ {\bf S_{1}.t:$\langle$assign-comp$\rangle =$ ecm}}


\subsection{Verbs with sentential subjects}
The following contrast involving complementizers surfaces with sentential
subjects:

\enumsentence{ *(That) John is crazy is likely.}

Indicative sentential subjects obligatorily have complementizers while
infinitival sentential subjects may or may not have a complementizer. 
Also {\em if} is possible as the complementizer of an object clause
but not as the complementizer of a sentential subject.

\enumsentence{ {\bf S_{1}.t:$\langle$comp$\rangle =$ that/whether/for/nil}}
\enumsentence{ {\bf S_{0}.t:$\langle$mode$\rangle =$ inf/ind}}
\enumsentence{ {\bf S_{1}.t:$\langle$assign-comp$\rangle =$ inf\_nil}}

If the sentential subject is finite and a complementizer does
not adjoin in, the {\bf $\langle$assign-comp$\rangle$} feature of the 
S_{0} node of the embedding clause and the root node of the
embedded clause will fail to unify. If a complementizer adjoins in,
there will be no feature-mismatch because the root of the
complementizer tree is not specified for the {\bf $\langle$assign-comp$\rangle$} feature.

The {\bf $\langle$comp$\rangle$} feature {\bf nil} is split into two
{\bf $\langle$assign-comp$\rangle$} features {\bf ind\_nil} and
{\bf inf\_nil} to capture the fact that there are certain configurations in
which it is acceptable for an infinitival clause to lack a complementizer
but not acceptable for an indicative clause to lack a complementizer. 

\subsection{{\em That}-trace and {\em for}-trace effects}

\enumsentence{ Who_{i} do you think (*that) t_{i} ate the apple?}

{\em That} trace violations are blocked by the presence of the following
equation:

\enumsentence{ {\bf S_{r}.b:$\langle$assign-comp$\rangle =$ inf\_nil/ind\_nil/ecm}}

on the bottom of the S_{r} nodes of trees with extracted subjects (W0). 
The {\bf ind\_nil} feature specification permits the above example
while the {\bf inf\_nil/ecm} feature specification allows the
following examples to be derived:

\enumsentence{ Who_{i} do you want [ t_{i} to win the World Cup]?}
\enumsentence{ Who_{i} do you consider [ t_{i} intelligent]?}

The feature equation that ruled out the {\em that}-trace filter violations
will also serve to rule out the {\em for}-trace violations above.

\section{Determiner ordering}
{\bf $\langle$card$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$compl$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$decreas$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$definite$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$gen$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$quan$\rangle$}, possible values are {\bf +, -}

For detailed discussion see the chapter on Determiners and Other
Noun Phrases.

\section{Punctuation}
{\bf $\langle$punct$\rangle$} is a complex feature. It has the following
as its subfeatures:\\
{\bf $\langle$punct bal$\rangle$}, possible values are {\bf dquote, squote, nil}\\
{\bf $\langle$punct contains dquote$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$punct contains squote$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$punct struct$\rangle$}, possible values are {\bf comma, dash, colon, 
none, nil}\\
{\bf $\langle$punct term$\rangle$}, possible values are {\bf per, qmark, excl, 
none, nil}

For detailed discussion see the chapter on Punctuation Marks.


\section{Conjunction}
{\bf $\langle$conj$\rangle$}, possible values are {\bf but, and, or, none, nil}\\
The {\bf $\langle$conj$\rangle$} feature is specified in the lexicon
for each conjunction and is passed up to the root node 
of the conjunction tree. If the conjunction is {\em and}, the 
root {\bf $\langle$agr num$\rangle$} is {\bf $\langle$plural$\rangle$}, no
matter what the number of the two conjuncts. With {\em or}, the
the root {\bf $\langle$agr num$\rangle$} is equated to the
{\bf $\langle$agr num$\rangle$} feature of the right conjunct. 


{\bf $\langle$disc-conj$\rangle$}, possible values are {\bf ind1, ind2, ind3, infl, infl2, ger, nil}\\
This feature is only used in the $\beta$CONJs tree.
It blocks the adjunction of one $\beta$CONJs tree on another.

\section{Comparatives}
{\bf $\langle$compar$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$equiv$\rangle$}, possible values are {\bf +, -}\\
{\bf $\langle$super$\rangle$}, possible values are {\bf +, -}

For detailed discussion see the chapter on Comparatives.

\section{Control}
{\bf $\langle$control$\rangle$}, no value, used only for indexing purposes.
The root node of every clausal tree has its {\bf $\langle$control$\rangle$}
feature coindexed with the control feature of its subject. 
This allows adjunct control to take place. In addition, clauses
that take infinitival clausal complements have the control
feature of their subject/object coindexed with the control feature
of their complement clause S, depending upon whether they are
subject control verbs or object control verbs respectively.


\section{Other Features}
{\bf $\langle$neg$\rangle$}, possible values are {\bf +, -}\\

{\bf $\langle$pred$\rangle$}, possible values are {\bf +, -}\\
The {\bf $\langle$pred$\rangle$} feature is used in the following tree
families: Tnx0N1.trees, Tnx0Px1s2.trees, and Tnx0nx1ARB.trees.
In the Tnx0N1.trees family, the following equations are used:\\
for $\beta$W1nx0N1:

\enumsentence{ NP_1.t:$\langle$pred$\rangle$ = +}
\enumsentence{ NP_1.b:$\langle$pred$\rangle$ = +}
\enumsentence{ NP.t:$\langle$pred$\rangle$ = +}
\enumsentence{ N.t:$\langle$pred$\rangle$ = NP.b:$\langle$pred$\rangle$}

This is the only tree in this tree family to use the 
{\bf $\langle$pred$\rangle$} feature.

This feature is also used with the Tnx0Px1s2.tree family. 
 Within this family, this feature (and the
following equations) are used only in the $\alpha$W1nx0Px1s

\enumsentence{ P_1.t:$\langle$pred$\rangle$ = +}
\enumsentence{ PP.b:$\langle$pred$\rangle$ = P.t:$\langle$pred$\rangle$}
\enumsentence{ P.t:$\langle$pred$\rangle$ = P_1.t:$\langle$pred$\rangle$}
\enumsentence{ P.t:$\langle$pred$\rangle$ = +}


The third tree family where the {\bf $\langle$$\langle$pred$\rangle$$\rangle$} feature is
used is Tnx0nx1ARB.trees.  Within this family, this feature (and the
following equations) are used only in the $\alpha$W1nx0nx1ARB tree.

\enumsentence{ AdvP_1.t:$\langle$pred$\rangle$ = +}
\enumsentence{ AdvP_1.b:$\langle$pred$\rangle$ = +}
\enumsentence{ NP.t:$\langle$pred$\rangle$ = +}
\enumsentence{ AdvP.b:$\langle$pred$\rangle$ = NP.t:$\langle$pred$\rangle$}


{\bf $\langle$pron$\rangle$}, possible values are {\bf +, -}\\
This feature indicates whether a particular NP is a pronoun or not. 
Certain constructions which do not permit pronouns use this 
feature to block pronouns.

{\bf $\langle$tense$\rangle$}, possible values are {\bf pres, past}\\
It does not seem to be the case that the {\bf $\langle$tense$\rangle$}
feature interacts with other features/syntactic processes. It 
comes from the lexicon with the verb and is transmitted up the
tree in such a way that the root S node ends up with the
tense feature of the highest verb in the tree. The equations
used for this purpose are:

\enumsentence{ {\bf S_r.b:$\langle$tense$\rangle$ = VP.t:$\langle$tense$\rangle$}}
\enumsentence{ {\bf VP.b:$\langle$tense$\rangle$ = V.t:$\langle$tense$\rangle$}}


{\bf $\langle$trans$\rangle$}, possible values are {\bf +, -}\\
Many but not all English verbs can anchor both transitive and intransitive trees.

\enumsentence{ The sun melted the ice cream.}
\enumsentence{ The ice cream melted.}
\enumsentence{ Elmo borrowed a book.}
\enumsentence{ * A book borrowed.}

Transitive trees have the {\bf $\langle$tense$\rangle$} feature of their
anchor set to {\ +} and intransitive trees have the 
{\bf $\langle$tense$\rangle$} feature of their
anchor set to {\ -}. Verbs such as {\em melt} which can occur 
in both transitive and intransitive trees come unspecified for the 
{\bf $\langle$trans$\rangle$} feature from the lexicon. Verbs which 
can only occur in transitive trees e.g. {\em borrow} have their
{\bf $\langle$tense$\rangle$} feature 
specified in the lexicon as {\bf +} thus blocking their anchoring of 
an intransitive tree.

